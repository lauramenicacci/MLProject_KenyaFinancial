{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"XGBoost.ipynb","provenance":[],"authorship_tag":"ABX9TyMa2sppWbmXitAqjsoXH8VQ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6PQVD0cNvPDE","executionInfo":{"status":"ok","timestamp":1650555979483,"user_tz":-120,"elapsed":2232,"user":{"displayName":"Laura Menicacci","userId":"16575933074778738670"}},"outputId":"869933c1-0f76-411f-d59d-dec4a0bf2f47"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/MyDrive/GRAD-C24_Machine_Learning/MLProject_KenyaFinancial\n"]}],"source":["# !pip install import-ipynb\n","\n","#access drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","%cd /content/drive/MyDrive/GRAD-C24_Machine_Learning/MLProject_KenyaFinancial\n","\n","x_path= \"/content/drive/MyDrive/GRAD-C24_Machine_Learning/MLProject_KenyaFinancial/clean_data/ohc3.csv\"\n","y_path= \"/content/drive/MyDrive/GRAD-C24_Machine_Learning/MLProject_KenyaFinancial/clean_data/depVar\"\n","\n"]},{"cell_type":"code","source":["%run Splitting_data.ipynb"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6M5hJcfZyRPA","executionInfo":{"status":"ok","timestamp":1650555985594,"user_tz":-120,"elapsed":4141,"user":{"displayName":"Laura Menicacci","userId":"16575933074778738670"}},"outputId":"300132f1-5f5c-42ff-85e9-b3793dbfab53"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","[Errno 2] No such file or directory: '/content/drive/MyDrive/GRAD-C24_Machine_Learning/MLProject_KenyaFinancial # Change path to yours'\n","/content/drive/MyDrive/GRAD-C24_Machine_Learning/MLProject_KenyaFinancial\n"]}]},{"cell_type":"code","source":["X_train, X_val, y_train, y_val = training_set(x_path, y_path)"],"metadata":{"id":"n6swBJNayRvZ","executionInfo":{"status":"ok","timestamp":1650556040575,"user_tz":-120,"elapsed":52060,"user":{"displayName":"Laura Menicacci","userId":"16575933074778738670"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["import xgboost\n","from matplotlib import pyplot as plt\n","\n","eval_set=[(X_train, y_train), (X_val, y_val)]\n","\n","xgb_reg = xgboost.XGBRegressor(n_estimators=3000,\n","                               max_depth=12,\n","                               subsample=1,\n","                               max_bin=500, # Maximum number of discrete bins to bucket continuous features. Increasing this number improves the optimality of splits at the cost of higher computation time.\n","                               objective=\"reg:squarederror\", # for iterative learning\n","                               eval_metric=\"rmse\", # for early-stopping evaluation using eval_set\n","                               early_stopping_rounds=10,\n","                               max_delta_step=0, # Maximum delta step we allow each leaf output to be. If the value is set to 0, it means there is no constraint. If it is set to a positive value, it can help making the update step more conservative. Usually this parameter is not needed, but it might help in logistic regression when class is extremely imbalanced. Set it to value of 1-10 might help control the update.\n","                               verbosity=1,\n","                               n_jobs=-1,\n","                              )\n","# see more parameters in https://xgboost.readthedocs.io/en/stable/parameter.html#parameters-for-tree-booster\n","\n","xgb_reg.fit(X_train, y_train, \n","            eval_set= eval_set, \n","            #verbose=False\n","           )\n","\n","results = xgb_reg.evals_result()\n","lowest_score = round(min(results[\"validation_1\"][\"rmse\"]), 2)\n","\n","print(f\"Optimal number of trees: {xgb_reg.best_ntree_limit}\\n RMSE: {lowest_score}\")\n","\n","# plot graph\n","plt.figure(figsize=(10,7))\n","plt.plot(results[\"validation_0\"][\"rmse\"], label=\"Training loss\")\n","plt.plot(results[\"validation_1\"][\"rmse\"], label=\"Validation loss\")\n","plt.axvline(xgb_reg.best_ntree_limit, color=\"gray\", label=\"Optimal tree number\")\n","plt.xlabel(\"Number of trees\")\n","plt.ylabel(\"Loss\")\n","plt.legend()"],"metadata":{"id":"-uszwQNqyHPg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["eval_set= [(X_train, y_train), (X_eval, )]"],"metadata":{"id":"CrYw5neyxJSM"},"execution_count":null,"outputs":[]}]}